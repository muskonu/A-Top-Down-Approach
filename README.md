# TASK-TWO
			一.概论
1.对可靠性要求更高使用TCP协议，对实时性要求更高使用UDP

2.网络各个层次相同层次之间有逻辑上的通信，不同层次之间有物理上的通信

3.网络(IP)层所提供的服务没有保障性(传输层帮助提供保障)

4.网络层为end to end(e2e)  链路层为 point to point(p2p)

5.物理层实现数据信号到物理信号的转变(media在物理层之下)

6.传统网络层分为路由和IP
路由器之间相互交换路由信息，按照路由选择算法算出路由表交给IP协议使用，
确定传输路径，然后对来到的信息进行转发

7.现代使用SDN(软件定义网络)有数据平面->交换机和控制平面->网络操作系统
控制平面运行网络应用计算流表，流表通过协议发送给交换机，交换机根据流表进行操作。
操作比传统更具多样化

8.互联网仅仅是网络的一种

9.网络为节点与边的一种拓扑，与形状，大小无关

10.节点有主机节点（画为方形）和数据交换节点(路由器，交换机等)（画为圆形）
数据交换节点既不是源也不是目标
路由器工作在网络层，交换机工作在链路层

11.边：通信链路     分为接入网链路和主干链路
接入网链路：主机连接到互联网的链路
主干链路：路由器间的链路

12.PDU 协议数据单元

13.从服务角度看互联网，互联网是由分布式的应用进程以及为应用进程提供通讯服务的基础设施
通信基础设施为apps提供api

14.网络结构：（1）网络边缘（2）网络核心（3）接入网，物理媒体->有线或无线通信链路

15.网络边缘   ：   C/S模式  客户端服务器模式  p2p（peer）模式->如迅雷

16.面向连接只有端系统知道，有连接是端系统和路径节点都知道
TCP面向连接 UDP无连接

17.网络核心      ：      电路交换   分组交换

18.电路交换（又称线路交换）：端到端的资源被分配给从源端到目标端的呼叫叫“call”，独享资源，不共享，
要求建立呼叫连接
（通常用于传统电话网络）
网络资源（如带宽）被分成片    时分（TDM）  频分（FDM）   波分（WDM）
电路交换不适合计算机之间的通信
	1.连接建立时间长
	2.计算机之间的通信有突发性，使用线路交换则浪费的片较多

19.分组交换：以分组（package）为单位进行存储-转发方式    资源共享，按需使用
	1.传输时使用全部的带宽
	2.延迟比线路交换更高（耽误存储时间和排队时间）
发送从发送者的角度是发送，从接收者角度是接收，是一个事物的两个方面
接收时间=发送时间+传输时间
分组交换为统计多路复用（特殊的时分）  A&B使用链路的模式不固定
分组交换允许更多的用户使用网络
分组交换按照有无网络层的连接分成虚电路网络和数据报网络
数据报  如Internet：
	根据分组的目标地址决定下一跳
	类似问路 
虚电路：
	主机和目标主机通信前先建立连接，交换节点之间保持通信状态
	
20.导引型媒体：信号沿着固体介质传播
   非导引型媒体：信号自由传播

22.POP：高层ISP面对客户用户的接入点，涉及费用结算
对等接入：两个ISP对等互接，不涉及费用结算
IXP：多个对等ISP互联互通之处，通常不涉及费用结算
ICP（内容提供商  如谷歌等）：自己部署专用网络，同时和各级ISP相连

23.四种分组延迟：节点处理延迟，排队延迟，传输延迟（打出数据所用时间），传播延迟（传输数据所用时间)
传输延迟：L（分组长度）/R（链路带宽）
传播延迟：d（物理链路长度）/s（媒体上的传输速度）
每一跳都要耽搁这四种延迟的组成
排队延迟：
	流量强度：L（分组长度）a（分组到达队列的平均速率）/R
	设计系统时流量强度不能大于1
	流量强度->1, 排队延时->无穷大
	（之所以传输速率>=到达速率还会有排队时延，是因为包到达时间的随机性）
	（随着持续时间的增大(20s,50s,...,100h,...)，排队时延会越来越大（排队的可能性也越来越大），到达速率是bits总数/总的t）

24.traceroute
	程序利用增加存活时间（TTL）（Time TO Live）值来实现其功能。每当数据包经过一个路由器，其存活时间就会减1。
	当其存活时间是0时，主机便取消数据包，并传送一个ICMPTTL数据包给原数据包的发出者。
	RTT（Round Trip Time）往返时间

25.分组丢失：当分组到达一个满的队列时，分组会被丢失
丢失的分组可能会被前一个节点或者源端重传或者根本不重传

26.吞吐量：在源端和目标端之间传输的速率（数据量/单位时间）
瞬间吞吐量：在一个时间点的速率
平均吞吐量：在一个长时间内平均值
瓶颈链路：端到端路径上，限制端到端吞吐的链路

27.协议是对等的水平关系，协议的实现借助与下层的服务，协议的目的是向上层实现更好的服务

28.服务（Service）：底层实体向上层实体提供它们之间的通信的能力
原语（primitive）：上层使用下层服务的形式，高层使用底层提供的服务以及低层向高层提供服务都是通过服务
访问原语来进行交互的
服务访问点SAP（Services Access Point）上层使用下层提供的服务通过层间的接口-地点
可以区分不同的服务用户

29.DU（数据单元）  SDU（服务数据单元）  SDU加上本层的控制信息就形成了本层的PDU（协议控制单元）ICI（接口控制信息）
SDU加上ICI传递给下层  head由本层和上层ICI告诉的消息转换形成
SDU过大会被分成多部分，每部分加上头部形成多个PDU
SDU过小也会被合并形成一个PDU

30.分层处理和实现复杂系统的好处
	1.概念化：结构清晰，便于标识网络组件，以及描述其相互关系
	2.模块化：易于维护和系统升级

31.分层思想被认为有害的地方：效率较低等

32.Internet协议栈
应用层：网络应用
	为人类用户或者其他应用进程提供网络应用服务
传输层：主机之间的数据传输
	在网络层提供的端（end）到端通信基础上，细分为进程到进程，将不可信的通信变成可靠的通信
网络层：为数据报从源到目的选择路由
	主机与主机之间的通信，端到端通信，不可靠
链路层：相邻网络节点间的数据传输
	两个相邻两个的通信，点到点通信，可靠或不可靠
物理层：在线路上传送bit
链路层和物理层一般一起封装在网卡
OSI还包括表示层（允许应用解释传输的数据）（eg.加密，压缩）和会话层（数据交换的同步，检查点，恢复）
在互联网中这些服务如果需要，需要被应用实现

33.各层次的PDU：应用层：报文（message）  传输层：报文段（segment）
网络层：分组（packet）（若无连接（如IP）：可叫数据报（datagram））   数据链路层：帧（frame）物理层：位（bit）






			二.应用层
1.应用层与传输层层间接口必须携带的信息：
	1.SDU
	2.自己的IP+TCP（UDP）端口
	3.对方的IP+TCP（UDP）端口
传输层实体根据这些信息进行TCP报文段封装
IP地址往下交，用于封装IP数据报

2.应用进程需解决的问题
	1.进程标示和寻址问题
	2.传输层-应用层如何提供服务
	3.如何使用传输层提供的服务

3.TCP socket：
TCP服务，两个进程之间的通信需要建立连接
可以用一个整数表示两个应用实体之间的通信
关系，充当本地标示。
源IP，源端口，目标IP，目标端口
应用使用这个标示与目标端进行通信
使通过层间的信息最少

4.UDP socket：
只包含自身端口和ip，不表示会话关系

5.应用层对于传输层所提供服务的要求：
	1.数据丢失率
	2.延迟
	3.吞吐
	4.安全性

6.HTTP1.0使用非持久连接
    HTTP1.1默认使用持久连接（流水方式）
响应时间：2RTT+对象传输时间
持久连接有流水线方式和非流水线方式
非流水线：一个对象响应之后请求下一个对象
流水线：不管响应就直接发送下一个请求直到发完

7.WEB缓存（代理服务器）

8.排队时间t=（I（流量强度）/1-I）*（L/R）

9.FTP协议有状态，控制命令和数据传输分别在两个TCP连接上进行

10.EMail由三个主要组成部分：用户代理，邮件服务器，简单邮件传输协议：SMTP

11.DNS提供的服务:
	1.提供了主机名到IP地址映射的查询服务
	2.提供主机别名（host aliasing）服务，DNS可以提供根据主机别名获取规范主机名的服务
	3.提供负载分配服务（load distribution）

12.域的划分是逻辑的，而不是物理的，一个域的主机可以不在一个网络

13.DNS服务器上存储着资源记录（Resource Record,  RR）, 资源记录是一个包含了下列字段的四元组：
（Name, Value, Type, TTL）
忽略TTL，Name和Value的的具体含义取决于Type：
Type = A，则Name是主机名，Value是该主机名对应的IP地址。 例如： （relay1.bar.foo.com, 145.37.93.126, A）

14.例子：
主机cis.poly.edu想知道主机gaia.cs.umass.edu的IP地址，并且
主机gaia.cs.umass.edu的权威DNS服务器为dns.umass.edu。
 
则DNS查询过程如下：
	1. 主机cis.poly.edu首先向它的本地DNS服务器dns.poly.edu发送一个DNS查询报文，该查询报文包含有要求转换的主机名gaia.cs.umass.edu
	2. 本地DNS服务器dns.poly.edu将该报文转发至根DNS服务器。
	3. 该根DNS服务器注意到DNS服务器的edu前缀并向本地DNS服务器dns.poly.edu返回负责edu的顶级域DNS服务器的IP地址列表
	4. 本地DNS服务器接收到了返回的报文，根据报文中的IP地址，向该顶级域DNS服务器发送查询报文
	5. 顶级域DNS服务器注意到了umass.edu前缀，用包含权威DNS服务器的IP地址进行响应，该权威DNS服务器是负责马萨诸塞大学的dns.umass.edu
	6. 本地DNS服务器直接向主机dns.umass.edu重发查询报文
	7. 主机dns.umass.edu使用gaia.cs.umass.edu的IP地址作为响应，传回给本地DNS服务器
	8. 最终，本地DNS服务器将包含最终结果的查询报文转发给请求主机cis.poly.edu

15.本地DNS服务器的作用
	1.主机和本地DNS服务器一般是相邻的，当主机发出DNS请求的时候，该请求会被发往本地DNS服务器，它起着代理的作用，并将该请求转发到DNS服务器层次结构中
	2.本地DNS服务器可以通过缓存主机名/IP地址，减少对相同主机名的查询而消耗的时间，改善时延和性能







				三.传输层
1.TCP提供服务：
	多路复用，解复用
	拥塞控制
	流量控制
	建立连接
   UDP提供服务：
	多路复用，解复用

2.UDP的PDU叫数据报

3.EDC（校验和）：判断是否丢失
校验失败一定出错，校验成功也有可能出错

4.选择UDP的原因：
	关于发送什么数据以及何时发送的应用层控制更为精细。
	无须连接建立。
	无连接状态。
	分组首部开销小。

5.虽然UDP提供差错检测，但它对差错恢复无能为力。

6.arq（自动重传请求）协议使用了肯定确认（ACK）和否定确认(NAK)

7.解决流水线的差错恢复有两种基本方法是：回退/V步（Go Back N,
GBN)和选择重传(Selective Repeat, SR)

8.GBN SW>1 RW=1
  SR SW>1 RW>1

9.对于SR协议而言，窗口长度必须小于或等于序号空间大小的一半。

10.TCP将应用层数据引导到该连接的发送缓存（sendbuffej里，发送缓存是发起三次
握手期间设置的缓存之一。TCP可从缓存中取出并放入报文段中的数据数量受限于最大报文段长度（Maximum Segment Size,
MSS）O MSS通常根据最初确定的由本地发送主机发送的最大链路层帧长度（即所谓的最
大传输单元（Maximum Transmission Unit, MTU））来设置。注意到MSS是
指在报文段里应用层数据的最大长度，而不是指包括首部的TCP报文段的最大长度。

11.TCP连接的组成包括：一台主机上的缓存、变量和与进
程连接的套接字，以及另一台主机上的另一组缓存、变量和与进程连接的套接字。

12.MSS：最大报文段大小  MSS通常根据最初确定的由本地发送主机发送的最大链路层帧长度（即所谓的最
大传输单元（Maximum Transmission Unit, MTU））来设置。

13.TCP不维护报文的界限，由应用进程维护

14.RTT偏差
DevRTT,用于估算SampleRTT 一般会偏离EstimatedRTT的程度：DevRTT = （1 -0） • DevRTT +0 • | SampleRTT - EstimatedRTT |
0的推荐值为0. 25。

15.TCP维持一个SampleRTT均值
（称为EstimatedRTT） o 一旦获得一个新SampleRTT时，TCP就会根据下列公式来更新Esti
matedRTT:
EstimatedRTT = （1 - a） • EstimatedRTT + a • SampleRTT
上面的公式是以编程语言的语句方式给出的，即EstimatedRTT的新值是由以前的EstimatedRTT值与SampleRTT新值加权组合而成的。在［RFC 6298 ］中给岀的a推荐值是
a =0.125 （即1/8）,这时上面的公式变为：
EstimatedRTT =0. 875 • EstimatedRTT +0. 125 • SampleRTT
这种平均被称为指数加权移动平均（Exponential Weighted Moving Average, EWMA）。

16. 重传超时间隔Timeoutinterval = EstinMrtedRTT +4 • DevRTT

17.每次TCP重传时都会将下一次的超时间隔设为先前值的两倍，
然而，每当定时器在另两个事件（即收到上层应用的数据和收到ACK）中的任意一个启动时，
Timeoutinterval由最近的EstimatedRTT 值与DevRTT值推算得到。

19.冗余ACK （duplicate ACK）就是再次确认某个报文段的ACK,而发送方先前
已经收到对该报文段的确认。
如果TCP发送方接收到对相同数据的3个冗余ACK,它
把这当作一种指示，说明跟在这个已被确认过3次的报文段之后的报文段已经丢失。
一旦收到3个冗余ACK, TCP就执行快速重传（fast retransmit）

20.一条TCP连接的每一侧主机都为该连接设置了接收缓存。
如果某应用程序读取数据时相对缓慢，而发送方发送得太多、太快，发送的数据就会
很容易地使该连接的接收缓存溢出。
TCP为它的应用程序提供了流流量控制服务(flow control service)以消除发送方使接收
方缓存溢岀的可能性。

21.TCP发送方也可能因为IP网络的拥塞而被遏
制；这种形式的发送方的控制被称为拥塞控制(congestion control)

22.TCP通过让发送方维护一个称为接收窗口(receive window)的变量来提供流量控制。
通俗地说，接收窗口用于给发送方一个指示一一该接收方还有多少可用的缓存空间。

23.• LastByteRead:主机B上的应用进程从缓存读出的数据流的最后一个字节的编号。
• LastByteRcvd:从网络中到达的并且已放入主机B接收缓存中的数据流的最后一个
字节的编号。
主机B为该连接分配了一个接收缓存，并用RcvBuffer来表示其大小。
接收窗口用rwnd表示，根据缓存可用空间的数量来设置:
rwnd = RcvBuffer - [ LastByteRcvd - LastByteRead ]

24.发送主机轮流跟踪两个变量，LastByteSent和LastByteAcked,
主机A在该连接的整个生命周期须保证:
LastByteSent 一 LastByteAcked ≤ rwnd

25.当主机B的接收窗口为0时，主机A继续发送只有一个字节数据的报文段。这
些报文段将会被接收方确认。最终缓存将开始清空，并且确认报文里将包含一个非0的
rwnd 值。

26.TCP的连接管理
| 事件  |   TCP接收方动作|
|--------|------|
|  具有所期望序号的按序报文段到达。所有在期望序号及以前的数据都已经被确认   |  延迟的ACK。对另一个按序报文段的到达最多等待500ms。如果下 一个按序报文段在这个时间间隔内没有到达，则发送一个ACK   |
| 具有所期望序号的按序报文段到达。另一个按序报文段等待ACK传输    |    立即发送单个累积ACK,以确认两个按序报文段 |
| 比期望序号大的失序报文段到达。检测出间隔    |     立即发送冗余ACK,指示下一个期待字节的序号（其为间隔的低端的序号） |
| 能部分或完全填充接收数据间隔的报文段到达 | 倘若该报文段起始于间隔的低端，则立即发送ACK |

27.SYN洪泛攻击
在这种攻击中，攻击者发送大量的TCP SYN报文段，而不完成第三次握手的步骤
现在有一种有效的防御系统，称为SYN cookie

28.当一台主机接收到一个TCP报文段，其端口号或源IP地址与
该主机上进行中的套接字都不匹配时，该主机将向源发送一个特殊
重置报文段。该TCP报文段将RST标志位置为1。

29.拥塞控制方法
	1.端到端拥塞控制
	2.•网络辅助的拥塞控制

对于网络辅助的拥塞控制，拥塞信息从网络反馈到发送方通常有两种方式，
	1直接反馈信息可以由网络路由器发给发送方。
	2.更为通用的第二种形式的通知
	是，路由器标记或更新从发送方流向接收方的分组中的某个字段来指示拥塞的产生口 一旦
	收到一个标记的分组后，接收方就会向发送方通知该网络拥塞指示。注意到后一种形式的
	通知至少要经过一个完整的往返时间。

30.运行在发送方的TCP拥塞控制机制跟踪一个额外的变量，即拥塞窗口
（congestion window） o拥塞窗口表示为cwnd,它对一个TCP发送方能向网络中发送流量的
速率进行了限制。

31.在一个发送方中未被确认的数据量不会超过cwnd与nvnd中的
最小值，即
LastByteSent 一 LastByteAcked ≤ min （ cwnd, rwnd ）

32.TCP的发送方收到对于以前未确认报文段的确
认，TCP将这些确认的到达作为一切正常的指示，即在网络上传输
的报文段正被成功地交付给目的地，并使用确认来增加窗口的长度（及其传输速率）。

33.因为TCP使用确认来触发（或计时）增大它的拥塞
窗口长度，TCP被说成是自计时（self-clocking）的。

34.TCP拥塞控制算法（TCP ongestion control algorithm），
该算法包括3个主要部分：①慢启动；②拥塞避免;
③快速恢复。慢启动和拥塞避免是TCP的强制部分，两者的差异在于对收到的ACK
做出反应时增加cwnd长度的方式。快速恢复是推荐部分，对TCP发送方并非是
必需的。

35.在慢启动（slow-start）状态，cwnd的值以1个MSS开始并且每当
传输的报文段首次被确认就增加1个MSS

36.		何时结束慢启动
如果存在一个由超时指示的丢包事件（即拥塞），TCP发送方将cwnd设置为1并重
新开始慢启动过程。它还将第二个状态变量的值ssthresh （"慢启动阈值”的速记）
设置为cwnd/2 ,即当检测到拥塞时将ssthresh置为拥塞窗口值的一半。

第二种方式是直接与ssthresh的值相关联。当cwnd的值等于ssthresh时，
结束慢启动并且TCP转移到拥塞避免模式。

37.最后一种结束慢启动的方式是,如果检测到3个冗余ACK,这时TCP执行一种快速重传，并进入快
速恢复状态

38.一旦进入拥塞避免状态，每个RTT只将cwnd的值增加一个MSS

一种通用的方法是对于TCP发送方无论何时到达一个新的确认，就将cwnd增加一个
MSS （ MSS/cwnd）字节。例如，如果MSS是1460字节并且cwnd是14 600字节，则在一
个R1T内发送10个报文段。每个到达ACK （假定每个报文段一个ACK）增加1/10MSS
的拥塞窗口长度，因此在收到对所有10个报文段的确认后，拥塞窗口的值将增加了一
个 MSS。

39.		应当结束拥塞避免的线性增长（每RTT 1MSS）呢？
当出现超时时，TCP的拥塞避免算法行为相同。与慢启动的情况一样，cwnd的值被设置为1个MSS,
ssthresh的值被更新为cwnd值的一半。

丢包事件也能由一个三个冗余ACK事件触发。在这种情况下，网络继续从发送方向接收方交付报文段（就像由收
到冗余ACK所指示的那样）。因此TCP对这种丢包事件的行为，相比于超时指示的丢包,
应当不那么剧烈：TCP将cwnd的值减半（为使测量结果更好，计及已收到的3个冗余的
ACK要加上3个MSS）,并且当收到3个冗余的ACK,将ssthresh的值记录为cwnd的值的
一半。接下来进入快速恢复状态。

40.在快速恢复中，对于引起TCP进入快速恢复状态的缺失报文段，对收到的每个冗余的
ACK, cwnd的值增加一个MSS。最终，当对丢失报文段的一个ACK到达时，TCP在降低
cwnd后进入拥塞避免状态。

41.TCP拥塞控制常常被称为加性增、乘性减（Additive- Increase, Multiplicative- Decrease，AIMD）拥塞控制方式。

42.在一个特定的往返间
隔内，TCP发送数据的速率是拥塞窗口与当前RTT的函数。当窗口长度是垃字节，且当
前往返时间是RTT秒时，则TCP的发送速率大约是w/RTT

43.当多条连接共享一个共同的瓶颈链路时，那些具有较小RTT的连接能够在链路空
闲时更快地抢到可用带宽（即较快地打开其拥塞窗口），因而将比那些具有较大RTT的连
接享用更高的吞吐量

			
44.接受端回应发送端中的win大小表示接受端还能够接受多少数据，发送端下次发送的数据大小不能超过回应中win的大小
win大小为0，表示接收端不能够再接受数据。

45.一般来说，每一次 write，都会将这一次的数据打包成一个或多个 TCP 报文段（如果数据量大于 MSS 的话，就会被打包成多个 TCP 段），并将最后一个 TCP 报文段标记为 PSH。
当然上面说的只是一般的情况，如果发送缓冲区满了，TCP 同样会将发送缓冲区中的所有数据打包发送。

如果接收方接收到了某个 TCP 报文段包含了 PSH 标志，则立即将缓冲区中的所有数据推送给应用进程（read 函数返回）。
当然有时候接收缓冲区满了，也会推送。




				四.网络层
			数据平面


1.网络层的作用从表面上看极为简单，即将分组从一台发送主机移动到一台接收主机。
为此，需要使用两种重要的网络层功能：
	•转发（转发是在数据平面中实现的唯一功能）
	•路由选择

2.每台网络路由器中有一个关键元素是它的转发表(forwarding table)。路由器检査到达
分组首部的一个或多个字段值，进而使用这些首部值在其转发表中索引，通过这种方法来转发分组。

路由选择算法决定了插入该路由器转发表的内容。在一台路由
器中的路由选择算法与在其他路由器中的路由选择算法通信，以计算出它的转发表的值

3.网络服务模型（network service model）定义了分组在发送与接收端系统之间的端到端运输特性。

因特网的网络层提供了单一的服务，称为尽力而为服务（best effort service）。使用尽
力而为服务，传送的分组既不能保证以它们发送的顺序被接收，也不能保证它们最终交
付；既不能保证端到端时延，也不能保证有最小的带宽。

4.分组交换机是指一台通用分组交换设备，它根据分组首部字段中的值，从输入链路
接口到输出链路接口转移分组。

某些分组交换机称为链路层交换机，基于链路层帧中的字段值做出转发决定，这些交换机因此被称为链路层（第2层）设备。其他分组交
换机称为路由器（router）,基于网络层数据报中的首部字段值做岀转发决定。路由器因此是网络层（第3层）设备。

5.一台路由器的4个组件：
	1.输入端口（input port）
	2.交换结构
	3.输出端口
	4.路由选择处理器（通常是一种传统的CPU）

6.交换结构位于一台路由器的核心部位,交换可以用许多方式完成：
	•经内存交换
	•经总线交换
	•经互联网络交换（非阻塞的（non-blocking））

7.排队的位置和程度（或者在输入端口排队，或者在输岀端口排队）将取
决于流量负载、交换结构的相对速率和线路速率。

8.输入排队交换机中的线路前部（Head-Of-the-Line, HOL）阻塞，即在一
个输入队列中排队的分组必须等待通过交换结构发送（即使输出端口是空闲
的），因为它被位于线路前部的另一个分组所阻塞。

9.输出端口排队：
	1.先进先出（FirstIn-First-Out, FIFO）
	2.优先权排队
	3.循环和 加权公平排队（WFQ）

10.协议号是将网络层与运输层绑定到一起的黏合剂，而端口号是将运输层和应用层绑定到一起的黏合剂。

11.一个链路层帧能承载的最大数据量叫作最大传送单元（Maximum Transmission Unit, MTU）。
在发送方与目的地路径上的每段链路可能使用不同的链路层协议，且每种协议可能具有不同的 MTU。 

解决该问题的方法是
将IP数据报中的数据分片成两个或更多个较小的IP数据报，用单独的链路层帧封装这
些较小的IP数据报，然后通过输出链路发送这些帧。每个这些较小的数据报都称为片(fragment) 

12.IPv4的设计者将标识、标志和片偏移字段放在IP数据报
首部中。当生成一个数据报时，发送主机在为该数据报设置源和目的地址的同时贴上标识
号。发送主机通常将它发送的每个数据报的标识号加1。当某路由器需要对一个数据报分
片时，形成的每个数据报（即片）具有初始数据报的源地址、目的地址与标识号。

为了让目的主机绝对地相信它已收到了初始数据报的最后一
个片，最后一个片的标志比特被设为0,而所有其他片的标志比特被设为1。另外，为了
让目的主机确定是否丢失了一个片（且能按正确的顺序重新组装片），使用偏移字段指定
该片应放在初始IP数据报的哪个位置。

13.主机与物理链路之间的边界叫作接口（inlerfkce）。路由器与它的任意一条链路之间的边界也叫作接口。
从技术上讲，一个IP地址与一个接口相关联，而不是与包括该接口的主机或路由器相关联。

14.为了确定子网，分开主机和路由器的每个接口，产生几个隔离的网络岛，使
用接口端接这些隔离的网络的端点。这些隔离的网络中的每一个都叫作一个子网
(subnet) 

15.因特网的地址分配策略被称为无类别域间路由选择(Classless Inlerdomain Routing,CIDR）

16.实践原则
	1.使用单个网络前缀通告多个网络的能力通常称
为地址聚合(address aggregation ),也称为路由聚合(route aggregation )或路由摘要
(route summarization)
	2.路由选择将使用最长前缀匹配

17.IP广播地址255. 255. 255. 255,当一台主机发出一个目的地址为255. 255. 255. 255的数据报时，该报文会交付给
同一个网络中的所有主机。路由器也会有选择地向邻近的子网转发该报文（虽然它们通常不这样做）。

18.为了获取一块IP地址用于一个组织的子网内，某网络管理员也许首先会与他的ISP联
系，该ISP可能会从已分给它的更大地址块中提供一些地址。

19.IP地址由ICANN管理，ICANN的作用不仅是分配IP地址，还管理DNS根服务器，同时分配域名与解决域名纷争。
ICANN向区域性因特网注册机构（如ARIN、RIPE、APNIC和LACNIC）分配地址，这些机构一起形成了 ICANN的地址支持组织［ASO-ICANN 2016］
,处理本区域内的地址分配/管理。

20.DHCP 允许主机自动获取（被分
配）一个IP地址。网络管理员能够配置DHCP,以使某给定主机每次与网络连接时能得到
一个相同的IP地址，或者某主机将被分配一个临时的IP地址（tempomry IP address）,每
次与网络连接时该地址也许是不同的。除了主机IP地址分配外，DHCP还允许一台主机得
知其他信息，例如它的子网掩码、它的第一跳路由器地址（常称为默认网关）与它的本地
DNS服务器的地址。

21.对于一台新到达的主机而言，针对图4-23所示的网络设置，DHCP协议是一个4个步骤的过程：
	• DHCP服务器发现。
	• DHCP服务器提供。
	• DHCP请求。
	• DHCP ACK。

22. IP地址0.0.0.0的作用
	1.当一台主机还没有被分配一个IP地址的时候，用于表示主机本身。（DHCP分配IP地址的时候）
	2.用作默认路由，表示”任意IPV4主机”。
	3.用来表示目标机器不可用。
	4.用作服务端，表示本机上的任意IPV4地址。

23.网络地址转换(Network Address Translation ,NAT)
具有专用地址的地域是指其地址仅对该网络中的设备有意义的网络。

如果从广域网到达NAT路由器的所有数据报都有相同的目的1P地址（特别是对NAT
路由器广域网一侧的接口），那么该路由器怎样知道它应将某个分组转发给哪个内部主机
呢？技巧就是使用NAT路由器上的一张NAT转换表（NAT translation t血e）,并且在表项
中包含了端口号及其IP地址。

24.IPv6不允许在中间路由器上进行分片与重新组装。这种操作只能
在源与目的地执行。

IPv6去掉了首部检验和。

25.在实践中已经得到广泛采用的IPv4到IPv6迁移的方法包括建隧道（tunneling）
我们将两台IPv6路由器之间的中间IPv4路由器的集
合称为一个隧道（tunnel）,如图4-27所示。借助于隧道，在隧道发送端的IPv6节点
（如B）可将整个IPv6数据报放到一个IPv4数据报的数据（有效载荷）字段中。

26.在通用转发中，一张匹配加动作表将我们在4. 2.1节中看到的基于目的地的转发表一
般化了。因为能够使用网络层和/或链路层源和目的地址做出转发决定，所以显示在图4-
28中的转发设备更为准确地描述为“分组交换机”而不是第三层“路由器”或第二层
“交换机”。这是在SDN文献中被广泛采用的术语。

27.匹配加动作转发表在OpenFlow中称为流表（ flow table）,它的每个表项包括:
	•首部字段值的集合，入分组将与之匹配。
	•计数器集合。
	•当分组匹配流表项时所采取的动作集合。

			控制平面


1.
